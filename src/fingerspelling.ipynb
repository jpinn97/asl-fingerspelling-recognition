{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read the first CSV file\n",
    "dataset_train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Read the second CSV file\n",
    "dataset_supplemental_df = pd.read_csv(\"supplemental_metadata.csv\")\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "dataset_df = pd.concat([dataset_train_df, dataset_supplemental_df], ignore_index=True)\n",
    "\n",
    "# Save the combined CSV file\n",
    "dataset_df.to_csv(\"train_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: train_landmarks/5414471.parquet, sequence_id: 1816796431, file_id: 5414471, phrase: 3 creekhouse\n",
      "Full sequence dataset shape is (123, 1630)\n"
     ]
    }
   ],
   "source": [
    "# Read the first row of the DataFrame\n",
    "path, sequence_id, file_id, phrase = dataset_df.iloc[0][\n",
    "    [\"path\", \"sequence_id\", \"file_id\", \"phrase\"]\n",
    "]\n",
    "print(f\"path: {path}, sequence_id: {sequence_id}, file_id: {file_id}, phrase: {phrase}\")\n",
    "\n",
    "sample_sequence_df = pq.read_table(\n",
    "    f\"{str(path)}\",\n",
    "    filters=[\n",
    "        [(\"sequence_id\", \"=\", sequence_id)],\n",
    "    ],\n",
    ").to_pandas()\n",
    "print(\"Full sequence dataset shape is {}\".format(sample_sequence_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 121\n"
     ]
    }
   ],
   "source": [
    "# Read the total amount unique files\n",
    "unique_paths = dataset_df[\"path\"].unique()\n",
    "\n",
    "sum = unique_paths.shape[0]\n",
    "\n",
    "print(\"Total number of files: {}\".format(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIP = [\n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "\n",
    "FACE = [f'x_face_{i}' for i in LIP] + [f'y_face_{i}' for i in LIP] + [f'z_face_{i}' for i in LIP]\n",
    "LHAND = [f'x_left_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)]\n",
    "RHAND = [f'x_right_hand_{i}' for i in range(21)] + [f'y_right_hand_{i}' for i in range(21)] + [f'z_right_hand_{i}' for i in range(21)]\n",
    "POSE = [f'x_pose_{i}' for i in range(33)] + [f'y_pose_{i}' for i in range(33)] + [f'z_pose_{i}' for i in range(33)]\n",
    "\n",
    "SEL_COLS = FACE + LHAND + RHAND + POSE\n",
    "FRAME_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆ| 121/121 [11:21<00:00,  5.63s/it, Writing 2100073719.tfrecord, sequence_id: 109101155\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from skimage.transform import resize\n",
    "\n",
    "pbar = tqdm(dataset_df.file_id.unique())\n",
    "\n",
    "for file_id in pbar:\n",
    "    file_df = dataset_df.loc[dataset_df[\"file_id\"] == file_id]\n",
    "\n",
    "    path = file_df[\"path\"].values[0]\n",
    "\n",
    "    parquet_df = pq.read_table(\n",
    "        path,\n",
    "        columns=[\"sequence_id\"] + SEL_COLS,\n",
    "    ).to_pandas()\n",
    "\n",
    "    tf_file = f\"preprocessed/{file_id}.tfrecord\"\n",
    "\n",
    "    parquet_numpy = parquet_df.to_numpy()\n",
    "    col_to_index = {col: i for i, col in enumerate(parquet_df.columns)}\n",
    "\n",
    "    # Convert LHAND and RHAND to lists of indices\n",
    "    LHAND_indices = [col_to_index[col] for col in LHAND]\n",
    "    RHAND_indices = [col_to_index[col] for col in RHAND]\n",
    "\n",
    "    with tf.io.TFRecordWriter(tf_file) as file_writer:\n",
    "        for seq_id, phrase in zip(file_df.sequence_id, file_df.phrase):\n",
    "            frames = parquet_numpy[parquet_df.index == seq_id]\n",
    "            \n",
    "            # Calculate the number of NaN values in each hand landmark\n",
    "            r_nonan = np.sum(np.sum(np.isnan(frames[:, RHAND_indices]), axis=1) == 0)\n",
    "            l_nonan = np.sum(np.sum(np.isnan(frames[:, LHAND_indices]), axis=1) == 0)\n",
    "            no_nan = max(r_nonan, l_nonan)\n",
    "\n",
    "            if 2 * len(phrase) < no_nan:\n",
    "                features = {\n",
    "                    COL: tf.train.Feature(\n",
    "                        float_list=tf.train.FloatList(\n",
    "                            value=frames[:, col_to_index[COL]]\n",
    "                        )\n",
    "                    )\n",
    "                    for COL in SEL_COLS\n",
    "                }\n",
    "\n",
    "                features[\"phrase\"] = tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(\n",
    "                        value=[bytes(phrase, \"utf-8\")],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Create a tf.train.Example\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "                # Serialize the example to a string\n",
    "                record_bytes = example.SerializeToString()\n",
    "\n",
    "                # Write the serialized example to a TFRecord file\n",
    "\n",
    "                pbar.set_postfix_str(\n",
    "                    f\"Writing {file_id}.tfrecord, sequence_id: {seq_id}}\"\n",
    "                )\n",
    "                file_writer.write(record_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
